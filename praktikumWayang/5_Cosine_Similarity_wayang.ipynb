{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measuring Cosine Similarity between Document Vectors Dengan Dataset Wayang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***kali ini kelompok kami mencoba dengan data manual tapi penyesuaian dengan data pada cerita wayang***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\IMAM\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\IMAM\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contoh Dataset Wayang\n",
    "pandawa003\n",
    "1. **Kalimat 1:**  \n",
    "   \"Kisah ini menceritakan tentang perkawinan antara Raden Gatutkaca putra Arya Wrekodara dengan Endang Pregiwa putri Raden Arjuna\"\n",
    "\n",
    "2. **Kalimat 2:**  \n",
    "   \"Kisah ini saya olah dari dongeng yang disampaikan orang tua saya, dengan sedikit pengembangan seperlunya\"\n",
    "\n",
    "3. **Kalimat 3:**  \n",
    "   \"Kediri, 31 Agustus 2017 Heri Purwanto Untuk daftar judul lakon wayang lainnya\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\"Kisah ini menceritakan tentang perkawinan antara Raden Gatutkaca putra Arya Wrekodara dengan Endang Pregiwa putri Raden Arjuna\",\n",
    "            \"Kisah ini saya olah dari dongeng yang disampaikan orang tua saya, dengan sedikit pengembangan seperlunya\",\n",
    "            \"Kediri, 31 Agustus 2017 Heri Purwanto Untuk daftar judul lakon wayang lainnya\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Kisah ini menceritakan tentang perkawinan anta...\n",
       "1    Kisah ini saya olah dari dongeng yang disampai...\n",
       "2    Kediri, 31 Agustus 2017 Heri Purwanto Untuk da...\n",
       "dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = pd.Series(sentences)\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_clean(corpus, keep_list):\n",
    "    cleaned_list = []\n",
    "    for row in corpus:\n",
    "        qs = []\n",
    "        for word in row.split():\n",
    "            if word not in keep_list:\n",
    "                p1 = re.sub(pattern='[^a-zA-Z0-9]',repl=' ',string=word)\n",
    "                p1 = p1.lower()\n",
    "                qs.append(p1)\n",
    "            else : qs.append(word)\n",
    "        cleaned_list.append(' '.join(qs))\n",
    "    return pd.Series(cleaned_list, dtype=\"string\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(corpus):\n",
    "    lem = WordNetLemmatizer()\n",
    "    corpus = [[lem.lemmatize(x, pos = 'v') for x in x] for x in corpus]\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(corpus, stem_type = None):\n",
    "    if stem_type == 'snowball':\n",
    "        stemmer = SnowballStemmer(language = 'english')\n",
    "        corpus = [[stemmer.stem(x) for x in x] for x in corpus]\n",
    "    else :\n",
    "        stemmer = PorterStemmer()\n",
    "        corpus = [[stemmer.stem(x) for x in x] for x in corpus]\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopwords_removal(corpus):\n",
    "    wh_words = ['who', 'what', 'when', 'why', 'how', 'which', 'where', 'whom']\n",
    "    stop = set(stopwords.words('english'))\n",
    "    for word in wh_words:\n",
    "        stop.remove(word)\n",
    "    corpus = [[x for x in x.split() if x not in stop] for x in corpus]\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(corpus, keep_list, cleaning = True, stemming = False, stem_type = None, lemmatization = False, remove_stopwords = True):\n",
    "\n",
    "    if cleaning == True:\n",
    "        corpus = text_clean(corpus, keep_list)\n",
    "\n",
    "    if remove_stopwords == True:\n",
    "        corpus = stopwords_removal(corpus)\n",
    "    else :\n",
    "        corpus = [[x for x in x.split()] for x in corpus]\n",
    "\n",
    "    if lemmatization == True:\n",
    "        corpus = lemmatize(corpus)\n",
    "\n",
    "\n",
    "    if stemming == True:\n",
    "        corpus = stem(corpus, stem_type)\n",
    "\n",
    "    corpus = [' '.join(x) for x in corpus]\n",
    "\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kisah ini menceritakan tentang perkawinan antara raden gatutkaca putra arya wrekodara dengan endang pregiwa putri raden arjuna',\n",
       " 'kisah ini saya olah dari dongeng yang disampaikan orang tua saya dengan sedikit pengembangan seperlunya',\n",
       " 'kediri 31 agustus 2017 heri purwanto untuk daftar judul lakon wayang lainnya']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_corpus = preprocess(corpus, keep_list = [], stemming = False, stem_type = None,\n",
    "                                lemmatization = True, remove_stopwords = True)\n",
    "preprocessed_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vector1, vector2):\n",
    "    vector1 = np.array(vector1)\n",
    "    vector2 = np.array(vector2)\n",
    "    return np.dot(vector1, vector2) / (np.sqrt(np.sum(vector1**2)) * np.sqrt(np.sum(vector2**2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "bow_matrix = vectorizer.fit_transform(preprocessed_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2017' '31' 'agustus' 'antara' 'arjuna' 'arya' 'daftar' 'dari' 'dengan'\n",
      " 'disampaikan' 'dongeng' 'endang' 'gatutkaca' 'heri' 'ini' 'judul'\n",
      " 'kediri' 'kisah' 'lainnya' 'lakon' 'menceritakan' 'olah' 'orang'\n",
      " 'pengembangan' 'perkawinan' 'pregiwa' 'purwanto' 'putra' 'putri' 'raden'\n",
      " 'saya' 'sedikit' 'seperlunya' 'tentang' 'tua' 'untuk' 'wayang'\n",
      " 'wrekodara' 'yang']\n",
      "[[0 0 0 1 1 1 0 0 1 0 0 1 1 0 1 0 0 1 0 0 1 0 0 0 1 1 0 1 1 2 0 0 0 1 0 0\n",
      "  0 1 0]\n",
      " [0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 2 1 1 0 1 0\n",
      "  0 0 1]\n",
      " [1 1 1 0 0 0 1 0 0 0 0 0 0 1 0 1 1 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1\n",
      "  1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.get_feature_names_out())\n",
    "print(bow_matrix.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine similarity between the document vectors built using CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine similarity between the documents  0 and 1 is:  0.16692446522239712\n",
      "The cosine similarity between the documents  0 and 2 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2 is:  0.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(bow_matrix.shape[0]):\n",
    "    for j in range(i + 1, bow_matrix.shape[0]):\n",
    "        print(\"The cosine similarity between the documents \", i, \"and\", j, \"is: \",\n",
    "              cosine_similarity(bow_matrix.toarray()[i], bow_matrix.toarray()[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "tf_idf_matrix = vectorizer.fit_transform(preprocessed_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2017' '31' 'agustus' 'antara' 'arjuna' 'arya' 'daftar' 'dari' 'dengan'\n",
      " 'disampaikan' 'dongeng' 'endang' 'gatutkaca' 'heri' 'ini' 'judul'\n",
      " 'kediri' 'kisah' 'lainnya' 'lakon' 'menceritakan' 'olah' 'orang'\n",
      " 'pengembangan' 'perkawinan' 'pregiwa' 'purwanto' 'putra' 'putri' 'raden'\n",
      " 'saya' 'sedikit' 'seperlunya' 'tentang' 'tua' 'untuk' 'wayang'\n",
      " 'wrekodara' 'yang']\n",
      "[[0.         0.         0.         0.23745536 0.23745536 0.23745536\n",
      "  0.         0.         0.18059092 0.         0.         0.23745536\n",
      "  0.23745536 0.         0.18059092 0.         0.         0.18059092\n",
      "  0.         0.         0.23745536 0.         0.         0.\n",
      "  0.23745536 0.23745536 0.         0.23745536 0.23745536 0.47491072\n",
      "  0.         0.         0.         0.23745536 0.         0.\n",
      "  0.         0.23745536 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.2520948  0.19172459 0.2520948  0.2520948  0.\n",
      "  0.         0.         0.19172459 0.         0.         0.19172459\n",
      "  0.         0.         0.         0.2520948  0.2520948  0.2520948\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.5041896  0.2520948  0.2520948  0.         0.2520948  0.\n",
      "  0.         0.         0.2520948 ]\n",
      " [0.28867513 0.28867513 0.28867513 0.         0.         0.\n",
      "  0.28867513 0.         0.         0.         0.         0.\n",
      "  0.         0.28867513 0.         0.28867513 0.28867513 0.\n",
      "  0.28867513 0.28867513 0.         0.         0.         0.\n",
      "  0.         0.         0.28867513 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.28867513\n",
      "  0.28867513 0.         0.        ]]\n",
      "\n",
      "The shape of the TF-IDF matrix is:  (3, 39)\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.get_feature_names_out())\n",
    "print(tf_idf_matrix.toarray())\n",
    "print(\"\\nThe shape of the TF-IDF matrix is: \", tf_idf_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine similarity between the documents  0 and 1 is:  0.10387116284571872\n",
      "The cosine similarity between the documents  0 and 2 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2 is:  0.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(tf_idf_matrix.shape[0]):\n",
    "    for j in range(i + 1, tf_idf_matrix.shape[0]):\n",
    "        print(\"The cosine similarity between the documents \", i, \"and\", j, \"is: \",\n",
    "              cosine_similarity(tf_idf_matrix.toarray()[i], tf_idf_matrix.toarray()[j]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
