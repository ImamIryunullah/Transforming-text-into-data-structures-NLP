{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words in Action dari Dataset Wayang\n",
    "\n",
    "M. Imam Iryunullah && Muhammad Azmi Nur Iman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ngeload Dataset Wayang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"output/pandawa_dataset_v2.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mengambil isi data pada json pada data answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "korpus = pd.Series([item[\"answer\"] for item in data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pabrik = StemmerFactory()\n",
    "stemmer = pabrik.create_stemmer()\n",
    "stop_kata = set(stopwords.words(\"indonesian\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pra_proses(korpus, daftar_tetap=None, stemming=True, jenis_stem=\"sastrawi\",\n",
    "               lemmatisasi=False, hapus_stopword=True):\n",
    "    hasil = []\n",
    "    \n",
    "    for teks in korpus:\n",
    "        teks = teks.lower()\n",
    "\n",
    "        if daftar_tetap:\n",
    "            for w in daftar_tetap:\n",
    "                teks = teks.replace(w.lower(), w.replace(\".\", \"\"))  \n",
    "\n",
    "        teks = re.sub(r\"\\d+\", \"\", teks)\n",
    "        teks = teks.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "\n",
    "        token = teks.split()\n",
    "\n",
    "        if hapus_stopword:\n",
    "            token = [t for t in token if t not in stop_kata]\n",
    "        if stemming and jenis_stem == \"sastrawi\":\n",
    "            token = [stemmer.stem(t) for t in token]\n",
    "        \n",
    "        if daftar_tetap:\n",
    "            for w in daftar_tetap:\n",
    "                token = [t if t != w.replace(\".\", \"\").lower() else w for t in token]\n",
    "        \n",
    "        hasil.append(\" \".join(token))\n",
    "    \n",
    "    return hasil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "kata_tetap = ['U.S.', 'Mr.', 'Mrs.', 'D.C.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pra_korpus = pra_proses(\n",
    "    korpus,\n",
    "    daftar_tetap=kata_tetap,\n",
    "    stemming=True,          \n",
    "    jenis_stem=\"sastrawi\",     \n",
    "    lemmatisasi=False,       \n",
    "    hapus_stopword=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kosa Kata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "kosakata_set = set()\n",
    "for kalimat in pra_korpus:\n",
    "    for kata in kalimat.split():\n",
    "        kosakata_set.add(kata)\n",
    "\n",
    "kosakata = list(kosakata_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buat Posisi Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "posisi = {}\n",
    "for i, token in enumerate(kosakata):\n",
    "    posisi[token] = i\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix Bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_matriks = np.zeros((len(pra_korpus), len(kosakata)))\n",
    "\n",
    "for i, kalimat in enumerate(pra_korpus):\n",
    "    for kata in kalimat.split():\n",
    "        bow_matriks[i][posisi[kata]] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- HASIL ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah dokumen : 33\n",
      "Ukuran kosakata: 2915\n",
      "Contoh matrix:\n",
      " [[ 0. 21.  0. ...  2.  0.  0.]\n",
      " [ 0.  0.  2. ...  4.  0.  0.]\n",
      " [ 0.  0.  0. ...  2.  0.  1.]\n",
      " [ 0.  0.  0. ...  8.  0.  0.]\n",
      " [ 0.  0.  1. ...  2.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Jumlah dokumen :\", bow_matriks.shape[0])\n",
    "print(\"Ukuran kosakata:\", bow_matriks.shape[1])\n",
    "print(\"Contoh matrix:\\n\", bow_matriks[:5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
