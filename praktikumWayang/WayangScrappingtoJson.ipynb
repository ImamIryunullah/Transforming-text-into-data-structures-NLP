{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Scrapping to JSON ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah cerita Pandawa ditemukan: 33\n",
      "Scraped: Sitija Takon Bapa\n",
      "Scraped: Abimanyu Rabi\n",
      "Scraped: Gatutkaca Rabi\n",
      "Scraped: Wahyu Cakraningrat\n",
      "Scraped: Gatutkaca Rante\n",
      "Scraped: Irawan Maling\n",
      "Scraped: Prabu Gambiranom\n",
      "Scraped: Irawan Rabi\n",
      "Scraped: Antasena Takon Bapa\n",
      "Scraped: Wisanggeni Lahir\n",
      "Scraped: Gandawardaya\n",
      "Scraped: Bambang Danasalira\n",
      "Scraped: Bratalaras Rabi\n",
      "Scraped: Sumitra Rabi\n",
      "Scraped: Endrasekti - Sugatawati\n",
      "Scraped: Samba Rabi\n",
      "Scraped: Bambang Pramusinta\n",
      "Scraped: Partajumena Rabi\n",
      "Scraped: Wisata Rabi\n",
      "Scraped: Petruk Nagih Janji\n",
      "Scraped: Wahyu Topeng Waja\n",
      "Scraped: Antareja Mbalela\n",
      "Scraped: Gatutkaca Jumeneng Ratu\n",
      "Scraped: Kikis Tunggarana\n",
      "Scraped: Purwaganti Takon Bapa\n",
      "Scraped: Prabu Tuguwasesa\n",
      "Scraped: Dewa Amral\n",
      "Scraped: Bimasuci\n",
      "Scraped: Gatutkaca Nagih Janji\n",
      "Scraped: Talirasa - Rasatali\n",
      "Scraped: Boma Rabi\n",
      "Scraped: Wisanggeni Rabi\n",
      "Scraped: Perang Gojalisuta\n",
      "Dataset sudah disimpan di output/pandawa_dataset_v2.json\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "base_url = \"https://albumkisahwayang.blogspot.com/2014/07/daftar-isi.html\"\n",
    "res = requests.get(base_url)\n",
    "soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "\n",
    "section = soup.find(\"b\", string=\"Kisah Pandawa dan Para Putra\")\n",
    "linkPandawa = []\n",
    "\n",
    "if section:\n",
    "    ul = section.find_next(\"ul\")\n",
    "    for i, a in enumerate(ul.find_all(\"a\", href=True)):\n",
    "        linkPandawa.append((f\"pandawa{i+1:03}\", a.text.strip(), a[\"href\"]))\n",
    "\n",
    "print(\"Jumlah cerita Pandawa ditemukan:\", len(linkPandawa))\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'\\s+', ' ', text)  \n",
    "    text = re.sub(r'\\[.*?\\]', '', text) \n",
    "    return text.strip()\n",
    "\n",
    "data = []\n",
    "\n",
    "infoKarakterNya = {\n",
    "    \"Pandawa\": [\"Yudhishthira\", \"Bhima\", \"Arjuna\", \"Nakula\", \"Sahadeva\"],\n",
    "    \"Arjuna\": [\"Pemuda pemanah ulung, sahabat Krishna, peran utama dalam Kurukshetra\"],\n",
    "    \"Bhima\": [\"Saudara Pandawa yang kuat, terkenal karena kekuatannya\"],\n",
    "    \"Krishna\": [\"Sahabat Pandawa, penyelamat, pembimbing spiritual Arjuna\"]\n",
    "}\n",
    "\n",
    "for asin, title, url in linkPandawa:\n",
    "    try:\n",
    "        page = requests.get(url)\n",
    "        page_soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "        content_div = page_soup.find(\"div\", class_=\"post-body\")\n",
    "        content = content_div.get_text(separator=\" \", strip=True) if content_div else \"\"\n",
    "        cleaned_content = clean_text(content)\n",
    "        word_count = len(cleaned_content.split())\n",
    "\n",
    "        karakterdiCerita = []\n",
    "        for character, descriptions in infoKarakterNya.items():\n",
    "            if character.lower() in title.lower():\n",
    "                karakterdiCerita.append({\n",
    "                    \"name\": character,\n",
    "                    \"description\": descriptions\n",
    "                })\n",
    "\n",
    "        unix_time = int(datetime.now().timestamp())\n",
    "\n",
    "        entry = {\n",
    "            \"asin\": asin,\n",
    "            \"question\": f\"Ceritakan tentang {title}\",\n",
    "            \"questionType\": \"open-ended\",\n",
    "            \"answer\": cleaned_content,\n",
    "            \"answerType\": \"informative\",\n",
    "            \"characters\": karakterdiCerita,\n",
    "            \"tags\": [\"Pandawa\", \"Wayang\", title],\n",
    "            \"metadata\": {\n",
    "                \"source_url\": url,\n",
    "                \"author\": \"Unspecified\",\n",
    "                \"date_published\": datetime.now().strftime('%Y-%m-%d'),\n",
    "                \"word_count\": word_count\n",
    "            },\n",
    "            \"categories\": [\"Perjalanan\", \"Perang\", \"Kehidupan Pandawa\"],\n",
    "            \"unixTime\": unix_time\n",
    "        }\n",
    "\n",
    "        data.append(entry)\n",
    "        print(\"Scraped:\", title)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Gagal scraping:\", title, \"-\", e)\n",
    "\n",
    "os.makedirs(\"output\", exist_ok=True)\n",
    "\n",
    "with open(\"output/pandawa_dataset_v2.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"Dataset sudah disimpan di output/pandawa_dataset_v2.json\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
